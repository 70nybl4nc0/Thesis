\begin{resumen}
    Existen numerosos entornos de evaluación de la capacidad de generalización para algoritmos de aprendizaje por refuerzo. En el contexto de la capacidad de generalización extrema similar a la humana hay pocos resultados. Debido a ello, es necesaria la implementación de entornos que contribuyan a un mejor modelo de evaluación para este tipo de algoritmos. En este trabajo se establecen las pautas de investigación y los conceptos primarios para el desarrollo a futuro de una plataforma para evaluación de agentes inteligentes y su justa comparación a los humanos.
\end{resumen}

\begin{abstract}
	There are many environments for evaluating generalization capabilities for reinforcement learning algorithms. In the context of human-like extreme generalization capabilities there are few results. Because of this, there is a need for the implementation of environments that contribute to a better evaluation model for this type of algorithms. This paper establishes the research guidelines and primary concepts for the future development of a platform for evaluation of intelligent agents and their fair comparison to humans.
\end{abstract}