@article{chollet2019measure,
  title   = {On the measure of intelligence},
  author  = {Chollet, Fran{\c{c}}ois},
  journal = {arXiv preprint arXiv:1911.01547},
  year    = {2019}
}

@inproceedings{10.1145/3311350.3357716,
  author    = {Hofmann, Katja},
  title     = {Minecraft as AI Playground and Laboratory},
  year      = {2019},
  isbn      = {9781450366885},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3311350.3357716},
  doi       = {10.1145/3311350.3357716},
  abstract  = {Modern video games provide exciting challenges and opportunities for pushing the state of the art in machine learning and other research areas, and, in turn, stand to first benefit from research advances. For driving research, games provide rich data that can be used to tackle hard problems, from complex decision making to collaboration. If and when these are successfully tackled, new algorithms and insights have the potential to enable entirely new game experiences.This talk focuses on opportunities in the setting of the game Minecraft, one of the most popular video games of all time. Minecraft is an open-world game, where players explore, create, and continuously find new ways to play and engage with each other. This open-ended nature both make the game appealing to its human fan-base, and uniquely challenging to AI algorithms. To unlock the potential of Minecraft for AI experimentation, my team has developed Project Malmo -- an open source experimentation platform built on top of Minecraft to enable a wide range of research. Here, I will illustrate the capabilities of the platform with recent examples that I find particularly exciting.I will highlight our most recent collaboration, led by a team of PhD students at Carnegie Mellon University: the MineRL competition. This ambitious competition is designed to drive advances in sample efficient reinforcement learning with human priors. Sample efficient learning is a key challenge, with current algorithms often requiring millions of samples to learn to perform individual narrow tasks, limiting the scope and applicability of these approaches. This competition is built around a complex task, large-scale demonstration data, and an evaluation setup that requires and rewards sample efficient learning and effective generalization.Looking out into the future, I will conclude by highlight selected open questions and challenges that have high potential for impact in video games and raise key questions for current state-of-the-art AI approaches.},
  booktitle = {Proceedings of the Annual Symposium on Computer-Human Interaction in Play},
  pages     = {1},
  numpages  = {1},
  keywords  = {video games, engagement, machine learning, minecraft, minerl, project malmo},
  location  = {Barcelona, Spain},
  series    = {CHI PLAY '19}
}

@inproceedings{guss2019the,
  author    = {Guss, William H and Codel, Cayden and Hofmann, Katja and Houghton, Brandon and Kuno, Noboru Sean and Milani, Stephanie and Mohanty, Sharada and Liebana, Diego Perez and Salakhutdinov, Ruslan and Topin, Nicholay and Veloso, Manuela and Wang, Philip},
  title     = {The MineRL Competition on Sample Efficient Reinforcement Learning using Human Priors},
  booktitle = {Thirty-third Conference on Neural Information Processing Systems (NeurIPS) Competition track},
  year      = {2019},
  month     = {December},
  abstract  = {Though deep reinforcement learning has led to breakthroughs in many difficult domains, these successes have required an ever-increasing number of samples. As state-of-the-art reinforcement learning (RL) systems require an exponentially increasing number of samples, their development is restricted to a continually shrinking segment of the AI community. Likewise, many of these systems cannot be applied to real-world problems, where environment samples are expensive. Resolution of these limitations requires new, sample-efficient methods. To facilitate research in this direction, we introduce the MineRL Competition on Sample Efficient Reinforcement Learning using Human Priors.
               
               The primary goal of the competition is to foster the development of algorithms which can efficiently leverage human demonstrations to drastically reduce the number of samples needed to solve complex, hierarchical, and sparse environments. To that end, we introduce:(1) the Minecraft ObtainDiamond task, a sequential decision making environment requiring long-term planning, hierarchical control, and efficient exploration methods; and (2) the MineRL-v0 dataset, a large-scale collection of over 60 million state-action pairs of human demonstrations that can be resimulated into embodied trajectories with arbitrary modifications to game state and visuals.},
  url       = {https://www.microsoft.com/en-us/research/publication/the-minerl-competition-on-sample-efficient-reinforcement-learning-using-human-priors/}
}

@article{wang2018glue,
  title   = {GLUE: A multi-task benchmark and analysis platform for natural language understanding},
  author  = {Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R},
  journal = {arXiv preprint arXiv:1804.07461},
  year    = {2018}
}

@article{bellemare2013arcade,
  title   = {The arcade learning environment: An evaluation platform for general agents},
  author  = {Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal = {Journal of Artificial Intelligence Research},
  volume  = {47},
  pages   = {253--279},
  year    = {2013}
}

@article{mccarthy1987generality,
  title     = {Generality in artificial intelligence},
  author    = {McCarthy, John},
  journal   = {Communications of the ACM},
  volume    = {30},
  number    = {12},
  pages     = {1030--1035},
  year      = {1987},
  publisher = {ACM New York, NY, USA}
}